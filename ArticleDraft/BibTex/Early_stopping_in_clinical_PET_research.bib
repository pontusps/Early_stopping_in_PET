Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Stefan2019,
abstract = {Well-designed experiments are likely to yield compelling evidence with efficient sample sizes. Bayes Factor Design Analysis (BFDA) is a recently developed methodology that allows researchers to balance the informativeness and efficiency of their experiment (Sch{\"{o}}nbrodt {\&} Wagenmakers, Psychonomic Bulletin {\&} Review, 25(1), 128–142 2018). With BFDA, researchers can control the rate of misleading evidence but, in addition, they can plan for a target strength of evidence. BFDA can be applied to fixed-N and sequential designs. In this tutorial paper, we provide an introduction to BFDA and analyze how the use of informed prior distributions affects the results of the BFDA. We also present a user-friendly web-based BFDA application that allows researchers to conduct BFDAs with ease. Two practical examples highlight how researchers can use a BFDA to plan for informative and efficient research designs.},
author = {Stefan, Angelika M. and Gronau, Quentin F. and Sch{\"{o}}nbrodt, Felix D. and Wagenmakers, Eric Jan},
doi = {10.3758/s13428-018-01189-8},
issn = {15543528},
journal = {Behavior Research Methods},
keywords = {Bayes factor,Design analysis,Power analysis,Sample size,Statistical evidence},
pmid = {30719688},
title = {{A tutorial on Bayes Factor Design Analysis using an informed prior}},
year = {2019}
}
@article{Rouder2014,
abstract = {Optional stopping refers to the practice of peeking at data and then, based on the results, deciding whether or not to continue an experiment. In the context of ordinary significance-testing analysis, optional stopping is discouraged, because it necessarily leads to increased type I error rates over nominal values. This article addresses whether optional stopping is problematic for Bayesian inference with Bayes factors. Statisticians who developed Bayesian methods thought not, but this wisdom has been challenged by recent simulation results of Yu, Sprenger, Thomas, and Dougherty (2013) and Sanborn and Hills (2013). In this article, I show through simulation that the interpretation of Bayesian quantities does not depend on the stopping rule. Researchers using Bayesian methods may employ optional stopping in their own research and may provide Bayesian analysis of secondary data regardless of the employed stopping rule. I emphasize here the proper interpretation of Bayesian quantities as measures of subjective belief on theoretical positions, the difference between frequentist and Bayesian interpretations, and the difficulty of using frequentist intuition to conceptualize the Bayesian approach.},
author = {Rouder, Jeffrey N.},
doi = {10.3758/s13423-014-0595-4},
issn = {15315320},
journal = {Psychonomic bulletin {\&} review},
pmid = {24659049},
title = {{Optional stopping: no problem for Bayesians}},
year = {2014}
}
@book{Dienes2008,
author = {Dienes, Zoltan},
isbn = {1137096055},
publisher = {Macmillan International Higher Education},
title = {{Understanding psychology as a science: An introduction to scientific and statistical inference}},
year = {2008}
}
@book{Gelman2013,
author = {Gelman, Andrew and Stern, Hal S and Carlin, John B and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
isbn = {1439898200},
publisher = {Chapman and Hall/CRC},
title = {{Bayesian data analysis}},
year = {2013}
}
@article{Lakens2013,
author = {Lakens, Dani{\"{e}}l},
doi = {10.3389/fpsyg.2013.00863},
issn = {16641078},
journal = {Frontiers in Psychology},
keywords = {Cohen's d, eta-squared,Effect sizes,Power analysis,Sample size planning},
title = {{Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs}},
year = {2013}
}
@article{Dienes2014,
author = {Dienes, Zoltan},
issn = {1664-1078},
journal = {Frontiers in psychology},
pages = {781},
publisher = {Frontiers},
title = {{Using Bayes to get the most out of non-significant results}},
volume = {5},
year = {2014}
}
@misc{VanDerAart2012,
abstract = {Intoduction: Carbon-11-labelled positron emission tomography (PET) tracers commonly used in biomedical research expose subjects to ionising radiation. Dosimetry is the measurement of radiation dose, but also commonly refers to the estimation of health risk associated with ionising radiation. This review describes radiation dosimetry of carbon-11-labelled molecules in the context of current PET research and the most widely used regulatory guidelines. Methods: A MEDLINE literature search returned 42 articles; 32 of these were based on human PET data dealing with radiation dosimetry of carbon-11 molecules. Radiation burden expressed as effective dose and maximum absorbed organ dose was compared between tracers. Results: All but one of the carbon-11-labelled PET tracers have an effective dose under 9 $\mu$Sv/MBq, with a mean of 5.9 $\mu$Sv/MBq. Data show that serial PET scans in a single subject are feasible for the majority of radiotracers. Conclusion: Although differing in approach, the two most widely used regulatory frameworks (those in the USA and the EU) do not differ substantially with regard to the maximum allowable injected activity per PET study. The predictive validity of animal dosimetry models is critically discussed in relation to human dosimetry. Finally, empirical PET data are related to human dose estimates based on homogenous distribution, generic models and maximum cumulated activities. Despite the contribution of these models to general risk estimation, human dosimetry studies are recommended where continued use of a new PET tracer is foreseen. {\textcopyright} 2012 Elsevier Inc.},
author = {{Van Der Aart}, Jasper and Hallett, William A. and Rabiner, Eugenii A. and Passchier, Jan and Comley, Robert A.},
booktitle = {Nuclear Medicine and Biology},
doi = {10.1016/j.nucmedbio.2011.08.005},
issn = {09698051},
keywords = {Dosimetry,Ionising radiation,Positron emission tomography (PET),Radiotracer,[11C]},
pmid = {22033023},
title = {{Radiation dose estimates for carbon-11-labelled PET tracers}},
year = {2012}
}
@article{Poldrack2017,
author = {Poldrack, Russell A and Baker, Chris I and Durnez, Joke and Gorgolewski, Krzysztof J and Matthews, Paul M and Munaf{\`{o}}, Marcus R and Nichols, Thomas E and Poline, Jean-Baptiste and Vul, Edward and Yarkoni, Tal},
issn = {1471-0048},
journal = {Nature Reviews Neuroscience},
number = {2},
pages = {115},
publisher = {Nature Publishing Group},
title = {{Scanning the horizon: towards transparent and reproducible neuroimaging research}},
volume = {18},
year = {2017}
}
@misc{Perezgonzalez2015,
abstract = {Despite frequent calls for the overhaul of null hypothesis significance testing (NHST), this controversial procedure remains ubiquitous in behavioral, social and biomedical teaching and research. Little change seems possible once the procedure becomes well ingrained in the minds and current practice of researchers; thus, the optimal opportunity for such change is at the time the procedure is taught, be this at undergraduate or at postgraduate levels. This paper presents a tutorial for the teaching of data testing procedures, often referred to as hypothesis testing theories. The first procedure introduced is Fisher's approach to data testing-tests of significance; the second is Neyman-Pearson's approach-tests of acceptance; the final procedure is the incongruent combination of the previous two theories into the current approach-NSHT. For those researchers sticking with the latter, two compromise solutions on how to improve NHST conclude the tutorial.},
author = {Perezgonzalez, Jose D.},
booktitle = {Frontiers in Psychology},
doi = {10.3389/fpsyg.2015.00223},
issn = {16641078},
keywords = {Fisher,NHST,Neyman-Pearson,Null hypothesis significance testing,Statistical education,Teaching statistics,Test of significance,Test of statistical hypotheses},
title = {{Fisher, Neyman-Pearson or NHST? A tutorial for teaching data testing}},
year = {2015}
}
@article{Ly2016,
abstract = {Harold Jeffreys pioneered the development of default Bayes factor hypothesis tests for standard statistical problems. Using Jeffreys's Bayes factor hypothesis tests, researchers can grade the decisiveness of the evidence that the data provide for a point null hypothesis H0 versus a composite alternative hypothesis H1. Consequently, Jeffreys's tests are of considerable theoretical and practical relevance for empirical researchers in general and for experimental psychologists in particular. To highlight this relevance and to facilitate the interpretation and use of Jeffreys's Bayes factor tests we focus on two common inferential scenarios: testing the nullity of a normal mean (i.e., the Bayesian equivalent of the t-test) and testing the nullity of a correlation. For both Bayes factor tests, we explain their development, we extend them to one-sided problems, and we apply them to concrete examples from experimental psychology.},
author = {Ly, Alexander and Verhagen, Josine and Wagenmakers, Eric Jan},
doi = {10.1016/j.jmp.2015.06.004},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
keywords = {Bayes factors,Harold Jeffreys,Model selection},
title = {{Harold Jeffreys's default Bayes factor hypothesis tests: Explanation, extension, and application in psychology}},
year = {2016}
}
@misc{Lakens2018,
author = {Lakens, Daniel and Adolfi, Federico G. and Albers, Casper J. and Anvari, Farid and Apps, Matthew A.J. and Argamon, Shlomo E. and Baguley, Thom and Becker, Raymond B. and Benning, Stephen D. and Bradford, Daniel E. and Buchanan, Erin M. and Caldwell, Aaron R. and {Van Calster}, Ben and Carlsson, Rickard and Chen, Sau Chin and Chung, Bryan and Colling, Lincoln J. and Collins, Gary S. and Crook, Zander and Cross, Emily S. and Daniels, Sameera and Danielsson, Henrik and Debruine, Lisa and Dunleavy, Daniel J. and Earp, Brian D. and Feist, Michele I. and Ferrell, Jason D. and Field, James G. and Fox, Nicholas W. and Friesen, Amanda and Gomes, Caio and Gonzalez-Marquez, Monica and Grange, James A. and Grieve, Andrew P. and Guggenberger, Robert and Grist, James and {Van Harmelen}, Anne Laura and Hasselman, Fred and Hochard, Kevin D. and Hoffarth, Mark R. and Holmes, Nicholas P. and Ingre, Michael and Isager, Peder M. and Isotalus, Hanna K. and Johansson, Christer and Juszczyk, Konrad and Kenny, David A. and Khalil, Ahmed A. and Konat, Barbara and Lao, Junpeng and Larsen, Erik Gahner and Lodder, Gerine M.A. and Lukavsk{\'{y}}, Jiř{\'{i}} and Madan, Christopher R. and Manheim, David and Martin, Stephen R. and Martin, Andrea E. and Mayo, Deborah G. and McCarthy, Randy J. and McConway, Kevin and McFarland, Colin and Nio, Amanda Q.X. and Nilsonne, Gustav and {De Oliveira}, Cilene Lino and {De Xivry}, Jean Jacques Orban and Parsons, Sam and Pfuhl, Gerit and Quinn, Kimberly A. and Sakon, John J. and Saribay, S. Adil and Schneider, Iris K. and Selvaraju, Manojkumar and Sjoerds, Zsuzsika and Smith, Samuel G. and Smits, Tim and Spies, Jeffrey R. and Sreekumar, Vishnu and Steltenpohl, Crystal N. and Stenhouse, Neil and {\'{S}}wi{\c{a}}tkowski, Wojciech and Vadillo, Miguel A. and {Van Assen}, Marcel A.L.M. and Williams, Matt N. and Williams, Samantha E. and Williams, Donald R. and Yarkoni, Tal and Ziano, Ignazio and Zwaan, Rolf A.},
booktitle = {Nature Human Behaviour},
doi = {10.1038/s41562-018-0311-x},
issn = {23973374},
title = {{Justify your alpha}},
year = {2018}
}
@article{Strube2006,
abstract = {The ease with which data can be collected and analyzed via personal computer makes it potentially attractive to "peek" at the data before a target sample size is achieved. This tactic might seem appealing because data collection could be stopped early, which would save valuable resources, if a peek revealed a significant effect Unfortunately, such data snooping comes with a cost When the null hypothesis is true, the Type I error rate is inflated, sometimes quite substantially. If the null hypothesis is false, premature significance testing leads to inflated estimates of power and effect size. This program provides simulation results for a wide variety of premature and repeated null hypothesis testing scenarios. It gives researchers the ability to know in advance the consequences of data peeking so that appropriate corrective action can be taken. Copyright 2006 Psychonomic Society, Inc.},
author = {Strube, Michael J.},
doi = {10.3758/BF03192746},
issn = {1554351X},
journal = {Behavior Research Methods},
pmid = {16817510},
title = {{SNOOP: A program for demonstrating the consequences of premature and repeated null hypothesis testing}},
year = {2006}
}
@article{Lakens2014,
abstract = {Running studies with high statistical power, while effect size estimates in psychology are often inaccurate, leads to a practical challenge when designing an experiment. This challenge can be addressed by performing sequential analyses while the data collection is still in progress. At an interim analysis, data collection can be stopped whenever the results are convincing enough to conclude that an effect is present, more data can be collected, or the study can be terminated whenever it is extremely unlikely that the predicted effect will be observed if data collection would be continued. Such interim analyses can be performed while controlling the Type 1 error rate. Sequential analyses can greatly improve the efficiency with which data are collected. Additional flexibility is provided by adaptive designs where sample sizes are increased on the basis of the observed effect size. The need for pre-registration, ways to prevent experimenter bias, and a comparison between Bayesian approaches and null-hypothesis significance testing (NHST) are discussed. Sequential analyses, which are widely used in large-scale medical trials, provide an efficient way to perform high-powered informative experiments. I hope this introduction will provide a practical primer that allows researchers to incorporate sequential analyses in their research.},
author = {Lakens, Dani{\"{e}}l},
doi = {10.1002/ejsp.2023},
issn = {10990992},
journal = {European Journal of Social Psychology},
title = {{Performing high-powered studies efficiently with sequential analyses}},
year = {2014}
}
@article{Kass1995,
author = {Kass, Robert E and Raftery, Adrian E},
issn = {0162-1459},
journal = {Journal of the american statistical association},
number = {430},
pages = {773--795},
publisher = {Taylor {\&} Francis Group},
title = {{Bayes factors}},
volume = {90},
year = {1995}
}
@book{Lee2014,
author = {Lee, Michael D and Wagenmakers, Eric-Jan},
isbn = {1107653916},
publisher = {Cambridge university press},
title = {{Bayesian cognitive modeling: A practical course}},
year = {2014}
}
@article{Benjamin2017,
author = {Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, Eric-Jan and Berk, Richard and Bollen, Kenneth A and Brembs, Bj{\"{o}}rn and Brown, Lawrence and Camerer, Colin},
journal = {Nature Human Behaviour},
title = {{Redefine statistical significance}},
year = {2017}
}
@article{Gonen2005,
abstract = {This article shows how the pooled-variance two-sample t statistic arises from a Bayesian formulation of the two-sided point null testing problem, with emphasis on teaching. We identify a reasonable and useful prior giving a closed-form Bayes factor that can be written in terms of the distribution of the two-sample t statistic under the null and alternative hypotheses, respectively. This provides a Bayesian motivation for the two-sample t statistic, which has heretofore been buried as a special case of more complex linear models, or given only roughly via analytic or Monte Carlo approximations. The resulting formulation of the Bayesian test is easy to apply in practice, and also easy to teach in an introductory course that emphasizes Bayesian methods. The priors are easy to use and simple to elicit, and the posterior probabilities are easily computed using available software, in some cases using spreadsheets. {\textcopyright} 2005 American Statistical Association.},
author = {G{\"{o}}nen, Mithat and Johnson, Wesley O. and Lu, Yonggang and Westfall, Peter H.},
doi = {10.1198/000313005X55233},
issn = {00031305},
journal = {American Statistician},
keywords = {Bayes factor,Posterior probability,Prior elicitation,Teaching Bayesian statistics},
title = {{The Bayesian two-sample t test}},
year = {2005}
}
@misc{Schulz2005,
abstract = {Subgroup analyses can pose serious multiplicity concerns. By testing enough subgroups, a false-positive result will probably emerge by chance alone. Investigators might undertake many analyses but only report the significant effects, distorting the medical literature. In general, we discourage subgroup analyses. However, if they are necessary, researchers should do statistical tests of interaction, rather than analyse every separate subgroup. Investigators cannot avoid interim analyses when data monitoring is indicated. However, repeatedly testing at every interim raises multiplicity concerns, and not accounting for multiplicity escalates the false-positive error. Statistical stopping methods must be used. The O'Brien-Fleming and Peto group sequential stopping methods are easily implemented and preserve the intended $\alpha$ level and power. Both adopt stringent criteria (low nominal p values) during the interim analyses. Implementing a trial under these stopping rules resembles a conventional trial, with the exception that it can be terminated early should a treatment prove greatly superior. Investigators and readers, however, need to grasp that the estimated treatment effects are prone to exaggeration, a random high, with early stopping.},
author = {Schulz, Kenneth F. and Grimes, David A.},
booktitle = {Lancet},
doi = {10.1016/S0140-6736(05)66516-6},
issn = {01406736},
pmid = {15885299},
title = {{Multiplicity in randomised trials II: Subgroup and interim analyses}},
year = {2005}
}
@article{Wrinch1921,
author = {Wrinch, Dorothy and Jeffreys, Harold},
issn = {1941-5982},
journal = {The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science},
number = {249},
pages = {369--390},
publisher = {Taylor {\&} Francis},
title = {{XLII. On certain fundamental principles of scientific inquiry}},
volume = {42},
year = {1921}
}
@article{Quintana2018,
abstract = {Background: Despite its popularity as an inferential framework, classical null hypothesis significance testing (NHST) has several restrictions. Bayesian analysis can be used to complement NHST, however, this approach has been underutilized largely due to a dearth of accessible software options. JASP is a recently developed open-source statistical package that facilitates both Bayesian and NHST analysis using a graphical interface. This article provides an applied introduction to Bayesian inference with Bayes factors using JASP. Methods: We use JASP to compare and contrast Bayesian alternatives for several common classical null hypothesis significance tests: correlations, frequency distributions, t-tests, ANCOVAs, and ANOVAs. These examples are also used to illustrate the strengths and limitations of both NHST and Bayesian hypothesis testing. Results: A comparison of NHST and Bayesian inferential frameworks demonstrates that Bayes factors can complement p-values by providing additional information for hypothesis testing. Namely, Bayes factors can quantify relative evidence for both alternative and null hypotheses. Moreover, the magnitude of this evidence can be presented as an easy-to-interpret odds ratio. Conclusions: While Bayesian analysis is by no means a new method, this type of statistical inference has been largely inaccessible for most psychiatry researchers. JASP provides a straightforward means of performing reproducible Bayesian hypothesis tests using a graphical "point and click" environment that will be familiar to researchers conversant with other graphical statistical packages, such as SPSS.},
author = {Quintana, Daniel S. and Williams, Donald R.},
doi = {10.1186/s12888-018-1761-4},
issn = {1471244X},
journal = {BMC Psychiatry},
keywords = {Bayesian analysis,Null hypothesis significance testing,Research methods,Software,Statistics,p-values},
pmid = {29879931},
title = {{Bayesian alternatives for common null-hypothesis significance tests in psychiatry: A non-technical guide using JASP}},
year = {2018}
}
@misc{Rouder2009,
abstract = {Progress in science often comes from discovering invariances in relationships among variables; these invariances often correspond to null hypotheses. As is commonly known, it is not possible to state evidence for the null hypothesis in conventional significance testing. Here we highlight a Bayes factor alternative to the conventional t test that will allow researchers to express preference for either the null hypothesis or the alternative. The Bayes factor has a natural and straightforward interpretation, is based on reasonable assumptions, and has better properties than other methods of inference that have been advocated in the psychological literature. To facilitate use of the Bayes factor, we provide an easy-to-use, Web-based program that performs the necessary calculations. {\textcopyright} 2009 The Psychonomic Society, Inc.},
author = {Rouder, Jeffrey N. and Speckman, Paul L. and Sun, Dongchu and Morey, Richard D. and Iverson, Geoffrey},
booktitle = {Psychonomic Bulletin and Review},
doi = {10.3758/PBR.16.2.225},
issn = {10699384},
pmid = {19293088},
title = {{Bayesian t tests for accepting and rejecting the null hypothesis}},
year = {2009}
}
@article{Svensson2019a,
author = {Svensson, Jonas E and Schain, Martin and Plav{\'{e}}n-Sigray, Pontus and Cervenka, Simon and Tiger, Mikael and Nord, Magdalena and Halldin, Christer and Farde, Lars and Lundberg, Johan},
issn = {1053-8119},
journal = {NeuroImage},
pages = {116143},
publisher = {Elsevier},
title = {{Validity and reliability of extrastriatal [11C] raclopride binding quantification in the living human brain}},
volume = {202},
year = {2019}
}
@article{Robert1996,
author = {Robert, Christian P. and Caron, Nathalie},
doi = {10.1007/bf02562626},
issn = {1133-0686},
journal = {Test},
title = {{Noninformative Bayesian testing and neutral Bayes factors}},
year = {1996}
}
@misc{Schulz2005,
abstract = {Subgroup analyses can pose serious multiplicity concerns. By testing enough subgroups, a false-positive result will probably emerge by chance alone. Investigators might undertake many analyses but only report the significant effects, distorting the medical literature. In general, we discourage subgroup analyses. However, if they are necessary, researchers should do statistical tests of interaction, rather than analyse every separate subgroup. Investigators cannot avoid interim analyses when data monitoring is indicated. However, repeatedly testing at every interim raises multiplicity concerns, and not accounting for multiplicity escalates the false-positive error. Statistical stopping methods must be used. The O'Brien-Fleming and Peto group sequential stopping methods are easily implemented and preserve the intended $\alpha$ level and power. Both adopt stringent criteria (low nominal p values) during the interim analyses. Implementing a trial under these stopping rules resembles a conventional trial, with the exception that it can be terminated early should a treatment prove greatly superior. Investigators and readers, however, need to grasp that the estimated treatment effects are prone to exaggeration, a random high, with early stopping.},
author = {Schulz, Kenneth F. and Grimes, David A.},
booktitle = {Lancet},
doi = {10.1016/S0140-6736(05)66516-6},
issn = {01406736},
pmid = {15885299},
title = {{Multiplicity in randomised trials II: Subgroup and interim analyses}},
year = {2005}
}
@article{Finnema2018,
abstract = {Synaptic vesicle glycoprotein 2A (SV2A) is ubiquitously present in presynaptic terminals. Here we report kinetic modeling and test–retest reproducibility assessment of the SV2A positron emission tomography (PET) radioligand [11C]UCB-J in humans. Five volunteers were examined twice on the HRRT after bolus injection of [11C]UCB-J. Arterial blood samples were collected for measurements of radiometabolites and free fraction. Regional time–activity curves were analyzed with 1-tissue (1T) and 2-tissue (2T) compartment models to estimate volumes of distribution (VT). Parametric maps were generated using the 1T model. [11C]UCB-J metabolized fairly quickly, with parent fraction of 36 ± 13{\%} at 15 min after injection. Plasma free fraction was 32 ± 1{\%}. Regional time–activity curves displayed rapid kinetics and were well described by the 1T model, except for the cerebellum and hippocampus. VT values estimated with the 2T model were similar to 1T values. Parametric maps were of high quality and VT values correlated well with time activity curve (TAC)-based estimates. Shortening of acquisition time from 120 min to 60 min had a negligible effect on VT values. The mean absolute test–retest reproducibility for VT was 3–9{\%} across regions. In conclusion, [11C]UCB-J exhibited excellent PET tracer characteristics and has potential as a general purpose tool for measuring synaptic density in neurodegenerative disorders.},
author = {Finnema, Sjoerd J. and Nabulsi, Nabeel B. and Mercier, Jo{\"{e}}l and Lin, Shu Fei and Chen, Ming Kai and Matuskey, David and Gallezot, Jean Dominique and Henry, Shannan and Hannestad, Jonas and Huang, Yiyun and Carson, Richard E.},
doi = {10.1177/0271678X17724947},
issn = {15597016},
journal = {Journal of Cerebral Blood Flow and Metabolism},
keywords = {Brain imaging,kinetic modeling,neurodegeneration,positron emission tomography,synapses/dendrites},
pmid = {28792356},
title = {{Kinetic evaluation and test–retest reproducibility of [11C]UCB-J, a novel radioligand for positron emission tomography imaging of synaptic vesicle glycoprotein 2A in humans}},
year = {2018}
}
@misc{Morey2018,
author = {Morey, Richard D. and Rouder, Jeffrey N.},
title = {{BayesFactor: Computation of Bayes Factors for Common Designs (v.0.9.12)}},
year = {2018}
}
@article{Rouder2014,
abstract = {Optional stopping refers to the practice of peeking at data and then, based on the results, deciding whether or not to continue an experiment. In the context of ordinary significance-testing analysis, optional stopping is discouraged, because it necessarily leads to increased type I error rates over nominal values. This article addresses whether optional stopping is problematic for Bayesian inference with Bayes factors. Statisticians who developed Bayesian methods thought not, but this wisdom has been challenged by recent simulation results of Yu, Sprenger, Thomas, and Dougherty (2013) and Sanborn and Hills (2013). In this article, I show through simulation that the interpretation of Bayesian quantities does not depend on the stopping rule. Researchers using Bayesian methods may employ optional stopping in their own research and may provide Bayesian analysis of secondary data regardless of the employed stopping rule. I emphasize here the proper interpretation of Bayesian quantities as measures of subjective belief on theoretical positions, the difference between frequentist and Bayesian interpretations, and the difficulty of using frequentist intuition to conceptualize the Bayesian approach.},
author = {Rouder, Jeffrey N.},
doi = {10.3758/s13423-014-0595-4},
issn = {15315320},
journal = {Psychonomic bulletin {\&} review},
pmid = {24659049},
title = {{Optional stopping: no problem for Bayesians}},
year = {2014}
}
@misc{Cohen1998,
address = {Hillsdale, NJ},
author = {Cohen, Jacob},
edition = {2nd ed},
publisher = {Erbaum},
title = {{Statistical power analysis for the behavioral sciences}},
year = {1998}
}
@book{Lee2014,
author = {Lee, Michael D and Wagenmakers, Eric-Jan},
isbn = {1107653916},
publisher = {Cambridge university press},
title = {{Bayesian cognitive modeling: A practical course}},
year = {2014}
}
@article{Schonbrodt2017,
author = {Sch{\"{o}}nbrodt, Felix D and Wagenmakers, Eric-Jan and Zehetleitner, Michael and Perugini, Marco},
issn = {1433890747},
journal = {Psychological methods},
number = {2},
pages = {322},
publisher = {American Psychological Association},
title = {{Sequential hypothesis testing with Bayes factors: Efficiently testing mean differences.}},
volume = {22},
year = {2017}
}
@misc{Rouder2009,
abstract = {Progress in science often comes from discovering invariances in relationships among variables; these invariances often correspond to null hypotheses. As is commonly known, it is not possible to state evidence for the null hypothesis in conventional significance testing. Here we highlight a Bayes factor alternative to the conventional t test that will allow researchers to express preference for either the null hypothesis or the alternative. The Bayes factor has a natural and straightforward interpretation, is based on reasonable assumptions, and has better properties than other methods of inference that have been advocated in the psychological literature. To facilitate use of the Bayes factor, we provide an easy-to-use, Web-based program that performs the necessary calculations. {\textcopyright} 2009 The Psychonomic Society, Inc.},
author = {Rouder, Jeffrey N. and Speckman, Paul L. and Sun, Dongchu and Morey, Richard D. and Iverson, Geoffrey},
booktitle = {Psychonomic Bulletin and Review},
doi = {10.3758/PBR.16.2.225},
issn = {10699384},
pmid = {19293088},
title = {{Bayesian t tests for accepting and rejecting the null hypothesis}},
year = {2009}
}
@article{VantVeer2016,
abstract = {Pre-registration of studies before they are conducted has recently become more feasible for researchers, and is encouraged by an increasing number of journals. However, because the practice of pre-registration is relatively new to psychological science, specific guidelines for the content of registrations are still in a formative stage. After giving a brief history of pre-registration in medical and psychological research, we outline two different models that can be applied—reviewed and unreviewed pre-registration—and discuss the advantages of each model to science as a whole and to the individual scientist, as well as some of their drawbacks and limitations. Finally, we present and justify a proposed standard template that can facilitate pre-registration. Researchers can use the template before and during the editorial process to meet article requirements and enhance the robustness of their scholarly efforts.},
author = {{van 't Veer}, Anna Elisabeth and Giner-Sorolla, Roger},
doi = {10.1016/j.jesp.2016.03.004},
issn = {10960465},
journal = {Journal of Experimental Social Psychology},
keywords = {Pre-registration,Research methods,Reviewed pre-registration (RPR),Solid science,Unreviewed pre-registration (UPR)},
title = {{Pre-registration in social psychology—A discussion and suggested template}},
year = {2016}
}
@article{Varnas2018,
author = {Varn{\"{a}}s, Katarina and Csel{\'{e}}nyi, Zsolt and Jucaite, Aurelija and Halldin, Christer and Svenningsson, Per and Farde, Lars and Varrone, Andrea},
issn = {1619-7070},
journal = {European journal of nuclear medicine and molecular imaging},
pages = {1--9},
publisher = {Springer},
title = {{PET imaging of [11 C] PBR28 in Parkinson's disease patients does not indicate increased binding to TSPO despite reduced dopamine transporter binding}},
year = {2018}
}
@article{Benjamin2017,
author = {Benjamin, Daniel J and Berger, James O and Johannesson, Magnus and Nosek, Brian A and Wagenmakers, Eric-Jan and Berk, Richard and Bollen, Kenneth A and Brembs, Bj{\"{o}}rn and Brown, Lawrence and Camerer, Colin},
journal = {Nature Human Behaviour},
title = {{Redefine statistical significance}},
year = {2017}
}
@article{Schonbrodt2018,
abstract = {A sizeable literature exists on the use of frequentist power analysis in the null-hypothesis significance testing (NHST) paradigm to facilitate the design of informative experiments. In contrast, there is almost no literature that discusses the design of experiments when Bayes factors (BFs) are used as a measure of evidence. Here we explore Bayes Factor Design Analysis (BFDA) as a useful tool to design studies for maximum efficiency and informativeness. We elaborate on three possible BF designs, (a) a fixed-n design, (b) an open-ended Sequential Bayes Factor (SBF) design, where researchers can test after each participant and can stop data collection whenever there is strong evidence for either ℋ1 or ℋ0, and (c) a modified SBF design that defines a maximal sample size where data collection is stopped regardless of the current state of evidence. We demonstrate how the properties of each design (i.e., expected strength of evidence, expected sample size, expected probability of misleading evidence, expected probability of weak evidence) can be evaluated using Monte Carlo simulations and equip researchers with the necessary information to compute their own Bayesian design analyses.},
author = {Sch{\"{o}}nbrodt, Felix D. and Wagenmakers, Eric Jan},
doi = {10.3758/s13423-017-1230-y},
issn = {15315320},
journal = {Psychonomic Bulletin and Review},
keywords = {Bayes factor,Design analysis,Design planning,Power analysis,Sequential testing},
pmid = {28251595},
title = {{Bayes factor design analysis: Planning for compelling evidence}},
year = {2018}
}
@article{Knudsen2020,
abstract = {It is a growing concern that outcomes of neuroimaging studies often cannot be replicated. To counteract this, the magnetic resonance (MR) neuroimaging community has promoted acquisition standards and created data sharing platforms, based on a consensus on how to organize and share MR neuroimaging data. Here, we take a similar approach to positron emission tomography (PET) data. To facilitate comparison of findings across studies, we first recommend publication standards for tracer characteristics, image acquisition, image preprocessing, and outcome estimation for PET neuroimaging data. The co-authors of this paper, representing more than 25 PET centers worldwide, voted to classify information as mandatory, recommended, or optional. Second, we describe a framework to facilitate data archiving and data sharing within and across centers. Because of the high cost of PET neuroimaging studies, sample sizes tend to be small and relatively few sites worldwide have the required multidisciplinary expertise to properly conduct and analyze PET studies. Data sharing will make it easier to combine datasets from different centers to achieve larger sample sizes and stronger statistical power to test hypotheses. The combining of datasets from different centers may be enhanced by adoption of a common set of best practices in data acquisition and analysis.},
author = {Knudsen, Gitte M. and Ganz, Melanie and Appelhoff, Stefan and Boellaard, Ronald and Bormans, Guy and Carson, Richard E. and Catana, Ciprian and Doudet, Doris and Gee, Antony D. and Greve, Douglas N. and Gunn, Roger N. and Halldin, Christer and Herscovitch, Peter and Huang, Henry and Keller, Sune H. and Lammertsma, Adriaan A. and Lanzenberger, Rupert and Liow, Jeih San and Lohith, Talakad G. and Lubberink, Mark and Lyoo, Chul H. and Mann, J. John and Matheson, Granville J. and Nichols, Thomas E. and N{\o}rgaard, Martin and Ogden, Todd and Parsey, Ramin and Pike, Victor W. and Price, Julie and Rizzo, Gaia and Rosa-Neto, Pedro and Schain, Martin and Scott, Peter J.H. and Searle, Graham and Slifstein, Mark and Suhara, Tetsuya and Talbot, Peter S. and Thomas, Adam and Veronese, Mattia and Wong, Dean F. and Yaqub, Maqsood and Zanderigo, Francesca and Zoghbi, Sami and Innis, Robert B.},
doi = {10.1177/0271678X20905433},
issn = {15597016},
journal = {Journal of Cerebral Blood Flow and Metabolism},
keywords = {Consensus guidelines,data sharing,data structure,open source,positron emission tomography},
pmid = {32065076},
title = {{Guidelines for the content and format of PET brain data in publications and archives: A consensus paper}},
year = {2020}
}
@article{Parsey2010,
abstract = {Background: Serotonin 1A receptors (5-HT1A) are implicated in major depressive disorder (MDD). We previously reported higher 5-HT1A binding potential (BPF) in antidepressant naive MDD subjects compared with control subjects, while other studies report lower BP ND. Discrepancies can be related to differences in study population or methodology. We sought to replicate our findings in a novel cohort and determine whether choice of reference region and outcome measure could explain discrepancies. Methods: Nine new control subjects and 22 new not recently medicated (NRM) MDD subjects underwent positron emission tomography. BP F and BPND were determined using a metabolite and free fraction corrected arterial input function. BPND was also determined using cerebellar gray matter (CGM) and cerebellar white matter (CWM) reference regions as input functions. Results: BPF was higher in thenewNRMcohort (p =.037) compared withnewcontrol subjects, comparable to the previous cohort (p {\textless}.04). Cohorts were combined to examine the reference region and outcome measure. BPF was higher in theNRMcompared with control subjects (p=.0001). Neither BPND usingCWM(p=.86) nor volume of distribution (VT) (p=.374) differed between groups. When CGM was used, the NRM group had lower 5-HT1A BPND compared with control subjects (p =.03); CGM VT was higher in NRM compared with control subjects (p =.007). Conclusions: Choice of reference region and outcome measure can produce different 5-HT1A findings. Higher 5-HT1A BPF in MDD was found with the method with fewest assumptions about nonspecific binding and a reference region without receptors. {\textcopyright} 2010 Society of Biological Psychiatry.},
author = {Parsey, Ramin V. and Ogden, R. Todd and Miller, Jeffrey M. and Tin, Adrienne and Hesselgrave, Natalie and Goldstein, Ellen and Mikhno, Arthur and Milak, Matthew and Zanderigo, Francesca and Sullivan, Gregory M. and Oquendo, Maria A. and Mann, J. John},
doi = {10.1016/j.biopsych.2010.03.023},
issn = {00063223},
journal = {Biological Psychiatry},
keywords = {Antidepressants,genotype,medication,modeling,polymorphism,unipolar},
pmid = {20497898},
title = {{Higher serotonin 1A binding in a second major depression cohort: Modeling and reference region considerations}},
year = {2010}
}
@article{McMahon2016,
abstract = {Cross-sectional neuroimaging studies in non-depressed individuals have demonstrated an inverse relationship between daylight minutes and cerebral serotonin transporter; this relationship is modified by serotonin-transporter-linked polymorphic region short allele carrier status. We here present data from the first longitudinal investigation of seasonal serotonin transporter fluctuations in both patients with seasonal affective disorder and in healthy individuals. Eighty 11C-DASB positron emission tomography scans were conducted to quantify cerebral serotonin transporter binding; 23 healthy controls with low seasonality scores and 17 patients diagnosed with seasonal affective disorder were scanned in both summer and winter to investigate differences in cerebral serotonin transporter binding across groups and across seasons. The two groups had similar cerebral serotonin transporter binding in the summer but in their symptomatic phase during winter, patients with seasonal affective disorder had higher serotonin transporter than the healthy control subjects (P = 0.01). Compared to the healthy controls, patients with seasonal affective disorder changed their serotonin transporter significantly less between summer and winter (P {\textless} 0.001). Further, the change in serotonin transporter was sex-(P = 0.02) and genotype-(P = 0.04) dependent. In the patients with seasonal affective disorder, the seasonal change in serotonin transporter binding was positively associated with change in depressive symptom severity, as indexed by Hamilton Rating Scale for Depression-Seasonal Affective Disorder version scores (P = 0.01). Our findings suggest that the development of depressive symptoms in winter is associated with a failure to downregulate serotonin transporter levels appropriately during exposure to the environmental stress of winter, especially in individuals with high predisposition to affective disorders.},
author = {{Mc Mahon}, Brenda and Andersen, Sofie B. and Madsen, Martin K. and Hjordt, Liv V. and Hageman, Ida and Dam, Henrik and Svarer, Claus and {Da Cunha-Bang}, Sofi and Baare, William and Madsen, Jacob and Hasholt, Lis and Holst, Klaus and Frokjaer, Vibe G. and Knudsen, Gitte M.},
doi = {10.1093/brain/aww043},
issn = {14602156},
journal = {Brain},
keywords = {PET,seasonal affective disorder,serotonin,serotonin transporter,serotonin transporter linked polymorphic region},
pmid = {26994750},
title = {{Seasonal difference in brain serotonin transporter binding predicts symptom severity in patients with seasonal affective disorder}},
year = {2016}
}
@article{Knudsen2020,
abstract = {It is a growing concern that outcomes of neuroimaging studies often cannot be replicated. To counteract this, the magnetic resonance (MR) neuroimaging community has promoted acquisition standards and created data sharing platforms, based on a consensus on how to organize and share MR neuroimaging data. Here, we take a similar approach to positron emission tomography (PET) data. To facilitate comparison of findings across studies, we first recommend publication standards for tracer characteristics, image acquisition, image preprocessing, and outcome estimation for PET neuroimaging data. The co-authors of this paper, representing more than 25 PET centers worldwide, voted to classify information as mandatory, recommended, or optional. Second, we describe a framework to facilitate data archiving and data sharing within and across centers. Because of the high cost of PET neuroimaging studies, sample sizes tend to be small and relatively few sites worldwide have the required multidisciplinary expertise to properly conduct and analyze PET studies. Data sharing will make it easier to combine datasets from different centers to achieve larger sample sizes and stronger statistical power to test hypotheses. The combining of datasets from different centers may be enhanced by adoption of a common set of best practices in data acquisition and analysis.},
author = {Knudsen, Gitte M. and Ganz, Melanie and Appelhoff, Stefan and Boellaard, Ronald and Bormans, Guy and Carson, Richard E. and Catana, Ciprian and Doudet, Doris and Gee, Antony D. and Greve, Douglas N. and Gunn, Roger N. and Halldin, Christer and Herscovitch, Peter and Huang, Henry and Keller, Sune H. and Lammertsma, Adriaan A. and Lanzenberger, Rupert and Liow, Jeih San and Lohith, Talakad G. and Lubberink, Mark and Lyoo, Chul H. and Mann, J. John and Matheson, Granville J. and Nichols, Thomas E. and N{\o}rgaard, Martin and Ogden, Todd and Parsey, Ramin and Pike, Victor W. and Price, Julie and Rizzo, Gaia and Rosa-Neto, Pedro and Schain, Martin and Scott, Peter J.H. and Searle, Graham and Slifstein, Mark and Suhara, Tetsuya and Talbot, Peter S. and Thomas, Adam and Veronese, Mattia and Wong, Dean F. and Yaqub, Maqsood and Zanderigo, Francesca and Zoghbi, Sami and Innis, Robert B.},
doi = {10.1177/0271678X20905433},
issn = {15597016},
journal = {Journal of Cerebral Blood Flow and Metabolism},
keywords = {Consensus guidelines,data sharing,data structure,open source,positron emission tomography},
pmid = {32065076},
title = {{Guidelines for the content and format of PET brain data in publications and archives: A consensus paper}},
year = {2020}
}
@article{VanDoorn2019,
author = {van Doorn, Johnny and van den Bergh, Don and Bohm, Udo and Dablander, Fabian and Derks, Koen and Draws, Tim and Evans, Nathan J and Gronau, Quentin Frederik and Hinne, Max and Kucharsk{\'{y}}, {\v{S}}imon},
publisher = {PsyArXiv},
title = {{The JASP guidelines for conducting and reporting a Bayesian analysis}},
year = {2019}
}
@article{Rouder2014,
abstract = {Optional stopping refers to the practice of peeking at data and then, based on the results, deciding whether or not to continue an experiment. In the context of ordinary significance-testing analysis, optional stopping is discouraged, because it necessarily leads to increased type I error rates over nominal values. This article addresses whether optional stopping is problematic for Bayesian inference with Bayes factors. Statisticians who developed Bayesian methods thought not, but this wisdom has been challenged by recent simulation results of Yu, Sprenger, Thomas, and Dougherty (2013) and Sanborn and Hills (2013). In this article, I show through simulation that the interpretation of Bayesian quantities does not depend on the stopping rule. Researchers using Bayesian methods may employ optional stopping in their own research and may provide Bayesian analysis of secondary data regardless of the employed stopping rule. I emphasize here the proper interpretation of Bayesian quantities as measures of subjective belief on theoretical positions, the difference between frequentist and Bayesian interpretations, and the difficulty of using frequentist intuition to conceptualize the Bayesian approach.},
author = {Rouder, Jeffrey N.},
doi = {10.3758/s13423-014-0595-4},
issn = {15315320},
journal = {Psychonomic bulletin {\&} review},
pmid = {24659049},
title = {{Optional stopping: no problem for Bayesians}},
year = {2014}
}
@article{Schonbrodt2017,
author = {Sch{\"{o}}nbrodt, Felix D and Wagenmakers, Eric-Jan and Zehetleitner, Michael and Perugini, Marco},
issn = {1433890747},
journal = {Psychological methods},
number = {2},
pages = {322},
publisher = {American Psychological Association},
title = {{Sequential hypothesis testing with Bayes factors: Efficiently testing mean differences.}},
volume = {22},
year = {2017}
}
@book{Jeffreys1961,
address = {Oxford},
author = {Jeffreys, H.},
edition = {3rd ed.},
publisher = {Oxford University Press},
title = {{Theory of probability}},
year = {1961}
}
@article{Kass1995,
author = {Kass, Robert E and Raftery, Adrian E},
issn = {0162-1459},
journal = {Journal of the american statistical association},
number = {430},
pages = {773--795},
publisher = {Taylor {\&} Francis Group},
title = {{Bayes factors}},
volume = {90},
year = {1995}
}
@article{Collste2016,
author = {Collste, K and Forsberg, A and Varrone, A and Amini, N and Aeinehband, S and Yakushev, I and Halldin, C and Farde, L and Cervenka, S.},
issn = {1619-7070},
journal = {European journal of nuclear medicine and molecular imaging},
number = {1},
pages = {173--183},
publisher = {Springer},
title = {{Test–retest reproducibility of [11C] PBR28 binding to TSPO in healthy control subjects}},
volume = {43},
year = {2016}
}
@article{Gronau2020,
abstract = {Across the empirical sciences, few statistical procedures rival the popularity of the frequentist (Formula presented.) -test. In contrast, the Bayesian versions of the (Formula presented.) -test have languished in obscurity. In recent years, however, the theoretical and practical advantages of the Bayesian (Formula presented.) -test have become increasingly apparent and various Bayesian t-tests have been proposed, both objective ones (based on general desiderata) and subjective ones (based on expert knowledge). Here, we propose a flexible t-prior for standardized effect size that allows computation of the Bayes factor by evaluating a single numerical integral. This specification contains previous objective and subjective t-test Bayes factors as special cases. Furthermore, we propose two measures for informed prior distributions that quantify the departure from the objective Bayes factor desiderata of predictive matching and information consistency. We illustrate the use of informed prior distributions based on an expert prior elicitation effort. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1704.02479},
author = {Gronau, Quentin F. and Ly, Alexander and Wagenmakers, Eric Jan},
doi = {10.1080/00031305.2018.1562983},
eprint = {1704.02479},
issn = {15372731},
journal = {American Statistician},
keywords = {Bayes factor,Informed hypothesis test,Prior elicitation},
title = {{Informed Bayesian t-Tests}},
year = {2020}
}
@article{Griffioen2018,
abstract = {Objective. A putative relationship between markers for the serotonin system and the personality scale self-transcendence (ST) and its subscale spiritual acceptance (SA) has been demonstrated in a previous PET study of 5-HT1A receptor binding in healthy control subjects. The results could however not be replicated in a subsequent PET study at an independent centre. In this study, we performed a replication of our original study in a larger sample using Bayesian hypothesis testing to evaluate relative evidence both for and against this hypothesis. Methods. Regional 5-HT1A receptor binding potential (BPND) was examined in 50 healthy male subjects using PET with the radioligand [11C]WAY100635. 5-HT1A availability was calculated using the simplified reference tissue model (SRTM) yielding regional BPND. ST and SA were measured using the Temperament and Character Inventory (TCI) questionnaire. Correlations between ST/SA scores and 5-HT1A BPND in frontal cortex, hippocampus and raphe nuclei were examined by calculation of default correlation Bayes factors (BFs) and replication BFs. Results. There were no significant correlations between 5-HT1A receptor binding and ST/SA scores. Rather, five of six replication BFs provided moderate to strong evidence for no association between 5-HT1A availability and ST/SA, while the remaining BF provided only weak evidence. Conclusion. We could not replicate our previous findings of an association between 5-HT1A availability and the personality trait ST/SA. Rather, the Bayesian analysis provided evidence for a lack of correlation. Further research should focus on whether other components of the serotonin system may be related to ST or SA. This study also illustrates how Bayesian hypothesis testing allows for greater flexibility and more informative conclusions than traditional p-values, suggesting that this approach may be advantageous for analysis of molecular imaging data.},
author = {Griffioen, Gina and Matheson, Granville J. and Cervenka, Simon and Farde, Lars and Borg, Jacqueline},
doi = {10.7717/peerj.5790},
issn = {21678359},
journal = {PeerJ},
keywords = {5-HT1A,Bayes theorem,Positron emission tomography,Replicability,Self-transcendence,Serotonin,Spirituality},
title = {{Serotonin 5-HT1A receptor binding and self-transcendence in healthy control subjects - A replication study using Bayesian hypothesis testing}},
year = {2018}
}
@article{Plaven-Sigray2018b,
author = {Plav{\'{e}}n-Sigray, Pontus and Matheson, Granville J and Collste, Karin and Ashok, Abhishekh H and Coughlin, Jennifer M and Howes, Oliver D and Mizrahi, Romina and Pomper, Martin G and Rusjan, Pablo and Veronese, Mattia and Wang, Yuchuan and Cervenka, Simon},
issn = {0006-3223},
journal = {Biological psychiatry},
number = {6},
pages = {433--442},
publisher = {Elsevier},
title = {{Positron Emission Tomography Studies of the Glial Cell Marker Translocator Protein in Patients With Psychosis: A Meta-analysis Using Individual Participant Data}},
volume = {84},
year = {2018}
}
@misc{Albers2019,
abstract = {In research studies, the need for additional samples to obtain sufficient statistical power has often to be balanced with the experimental costs. One approach to this end is to sequentially collect data until you have sufficient measurements, e.g., when the p-value drops below 0.05. I outline that this approach is common, yet that unadjusted sequential sampling leads to severe statistical issues, such as an inflated rate of false positive findings. As a consequence, the results of such studies are untrustworthy. I identify the statistical methods that can be implemented in order to account for sequential sampling.},
author = {Albers, Casper},
booktitle = {Nature Communications},
doi = {10.1038/s41467-019-09941-0},
issn = {20411723},
pmid = {31015469},
title = {{The problem with unadjusted multiple and sequential statistical testing}},
year = {2019}
}
@article{Chen2019,
author = {Chen, Y and Goldsmith, J and Ogden, T},
doi = {10.1109/TBME.2018.2861875},
issn = {0018-9294 VO  -},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Analytical models,Biomedical measurement,Blood,Buildings,Compartment model,Data models,Kinetic theory,Model building,Nonlinear least squares,Standards},
pages = {1},
title = {{Nonlinear Mixed-Effects Models for PET Data}},
year = {2019}
}
@article{Dienes2014,
author = {Dienes, Zoltan},
issn = {1664-1078},
journal = {Frontiers in psychology},
pages = {781},
publisher = {Frontiers},
title = {{Using Bayes to get the most out of non-significant results}},
volume = {5},
year = {2014}
}
@article{Nord2014,
abstract = {Purpose: [11C]AZ10419369 is a recently developed 5-HT 1B receptor radioligand that is sensitive to changes in endogenous serotonin concentrations in the primate brain. Thus, [11C] AZ10419369 may serve as a useful tool in clinical studies of the pathophysiology and pharmacological treatment of diseases related to the serotonin system, such as depression and anxiety disorders. The aim of this study was to evaluate the test-retest reliability of [11C]AZ10419369. Methods: Eight men were examined with PET and [11C] AZ10419369 twice on the same day. The binding potentials (BPND) of [11C]AZ10419369 in selected serotonergic projection areas and in the raphe nuclei (RN) were determined using the simplified reference tissue model, and for comparison also using a wavelet-aided parametric imaging approach. The BPND values obtained from the first and second PET scans were compared by means of descriptive statistics, difference, absolute variability and intraclass correlation coefficient. Results: Similar BPND values were obtained with the two methods. The absolute mean differences in BPND between PET 1 and PET 2 were less than 3 {\%} in all serotonergic projection regions. Absolute variabilities were low in cortical regions (5 - 7 {\%}), low to moderate (7 - 14 {\%}) in subcortical regions, but higher (20 {\%}) in the RN. Conclusion: The BP ND of [11C]AZ10419369 is highly reproducible in cortical regions and satisfactory in subcortical projection areas. The variability in the RN is higher. Thus larger sample sizes or larger divergences are required to assess a potential difference between subjects or between experimental conditions in this region. {\textcopyright} Springer-Verlag Berlin Heidelberg 2013.},
author = {Nord, Magdalena and Finnema, Sjoerd J. and Schain, Martin and Halldin, Christer and Farde, Lars},
doi = {10.1007/s00259-013-2529-1},
issn = {16197089},
journal = {European Journal of Nuclear Medicine and Molecular Imaging},
keywords = {Brain Imaging,PET,Test-retest},
number = {2},
pages = {301--307},
pmid = {24006152},
title = {{Test-retest reliability of [11C]AZ10419369 binding to 5-HT 1B receptors in human brain}},
volume = {41},
year = {2014}
}
@article{Love2019,
abstract = {This paper introduces JASP, a free graphical software package for basic statistical procedures such as t tests, ANOVAs, linear regression models, and analyses of contingency tables. JASP is open-source and differentiates itself from existing open-source solutions in two ways. First, JASP provides several innovations in user interface design; specifically, results are provided immediately as the user makes changes to options, output is attractive, minimalist, and designed around the principle of progressive disclosure, and analyses can be peer reviewed without requiring a “syntax”. Second, JASP provides some of the recent developments in Bayesian hypothesis testing and Bayesian parameter estimation. The ease with which these relatively complex Bayesian techniques are available in JASP encourages their broader adoption and furthers a more inclusive statistical reporting practice. The JASP analyses are implemented in R and a series of R packages.},
author = {Love, Jonathon and Selker, Ravi and Marsman, Maarten and Jamil, Tahira and Dropmann, Damian and Verhagen, Josine and Ly, Alexander and Gronau, Quentin F. and {\v{S}}m{\'{i}}ra, Martin and Epskamp, Sacha and Matzke, Dora and Wild, Anneliese and Knight, Patrick and Rouder, Jeffrey N. and Morey, Richard D. and Wagenmakers, Eric Jan},
doi = {10.18637/jss.v088.i02},
issn = {15487660},
journal = {Journal of Statistical Software},
keywords = {Basic statistics,Bayesian inference,Graphical user interface,JASP,Statistical software},
title = {{JASP: Graphical statistical software for common statistical designs}},
year = {2019}
}
